{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 머신 러닝의 네 가지 분류\n",
    "\n",
    "#### 4.1.1 지도 학습\n",
    "\n",
    "가장 흔한 경우   \n",
    "샘플 데이터가 주어지면 알고 있는 타깃에 입력 데이터를 매핑하는 방법을 학습함   \n",
    "문자 판독, 음성 인식, 이미지 분류, 언어 번역과 같이 딥러닝의 거의 모든 애플리케이션이 여기에 속함\n",
    "\n",
    "대부분 분류와 회귀로 구성됨\n",
    "\n",
    "지도 학습의 변종\n",
    "- 시퀀스 생성: 사진이 주어지면 이를 설명하는 캡션을 생성함, 종종 일련의 분류 문제로 재구성할 수 있음\n",
    "- 구문 트리 예측: 문장이 주어지면 분해된 구문 트리를 예측함\n",
    "- 물체 감지: 사진이 주어지면 사진 안의 특정 물체 주위에 경계 상자를 그림   \n",
    "             (분류 문제/(경계 상자의 좌표를 벡터 회귀로 예측하는)회귀와 분류 결합된 문제로 표현 가능\n",
    "- 이미지 분할: 사진이 주어졌을 때 픽셀 단위로 특정 물체에 마스킹함\n",
    "\n",
    "\n",
    "#### 4.1.2 비지도 학습\n",
    "\n",
    "어떤 타깃도 사용하지 않고 입력 데이터에 대한 변환을 찾음   \n",
    "데이터 시각화, 데이터 압축, 데이터의 노이즈 제거, 데이터에 있는 상관관계를 더 잘 이해하기 위해 사용함   \n",
    "지도 학습 문제를 풀기 전, 데이터셋을 이해하기 위해 필수적으로 거치는 단계임   \n",
    "\n",
    "잘 알려진 범주: 차원 축소, 군집\n",
    "\n",
    "\n",
    "#### 4.1.3 자기 지도 학습\n",
    "\n",
    "지도 학습의 특별한 경우   \n",
    "사람이 만든 레이블을 사용하지 않음(학습 과정에 사람이 개입 x)   \n",
    "경험적인 알고리즘을 사용해 입력 데이터로부터 생성함\n",
    "\n",
    "예시\n",
    "- 오토인코더 (생성된 타깃은 수정하지 않은 원본 입력임)\n",
    "- 지난 프레임이 주어졌을 때 비디오의 다음 프레임 예측하는 것\n",
    "- 이전 단어 주어졌을 때 다음 단어 예측하는 것(미래의 입력 데이터로부터 지도돼서 시간에 따른 지도학습임)\n",
    "\n",
    "학습 메커니즘과 애플리케이션 측면 중 어디에 중점 두는지에 따라 지도 학습/ 비지도 학습으로 재해석 가능함\n",
    "\n",
    "\n",
    "#### 4.1.4 강화학습\n",
    "\n",
    "에이전트: 환경에 대한 정보를 받아 보상 최대화하는 행동 선택하도록 학습됨   \n",
    "\n",
    "        ex) 강화 학습으로 훈련된 신경망은 비디오 게임 화면을 입력으로 받고 게임 점수를 최대화하기 위한 게임 내의 행동 출력 가능함\n",
    "        \n",
    "대부분 연구 영역에 속해 있으며 게임 이외에 실제적인 성공 사례는 아직 없음   \n",
    "하지만 나중에는 실제 세상의 많은 애플리케이션 대체할 것이라고 기대하고 있음(자율 주행 자동차, 자원 관리, 교육 등)\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "**분류와 회귀에서 사용하는 용어**   \n",
    "- 샘플(입력): 모델에 주입될 하나의 데이터 포인트\n",
    "- 예측(출력): 모델로부터 나오는 값\n",
    "- 타깃: 정답(모델이 예측해야 하는 값)\n",
    "- 예측 오차(손실 값): 모델의 예측과 타깃 사이의 거리를 측정한 값\n",
    "- 클래스: 분류 문제에서 선택 가능한 레이블의 집합\n",
    "- 레이블: 분류 문제에서 클래스 할당의 구체적인 사례\n",
    "- 참 값(꼬리표): 데이터셋에 대한 모든 타깃(일반적으로 사람에 의해 수집됨)\n",
    "- 이진 분류: 입력 샘플이 2개의 배타적 범주로 구분되는 분류 작업\n",
    "- 다중 분류: 입력 샘플이 2개 이상의 범주로 구분되는 분류 작업\n",
    "- 다중 레이블 분류: 입력 샘플이 여러 개의 레이블에 할당 가능한 분류 작업\n",
    "- 스칼라 회귀: 타깃이 연속적인 스칼라 값인 작업(주택 가격 예측)\n",
    "- 벡터 회귀: 타깃이 연속적인 값의 집합인 작업(연속적인 값으로 이뤄진 벡터, 여러 개의 값에 대한 회귀)\n",
    "- 미니 배치(배치): 모델에 의해 동시에 처리되는 소량의 샘플 묶음(8~128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 머신 러닝 모델 평가\n",
    "\n",
    "#### 4.2.1 훈련, 검증, 테스트 세트\n",
    "\n",
    "모델 평가에서 가용한 데이터를 항상 훈련, 검증, 테스트 3개의 세트로 나눔   \n",
    "훈련 세트와 테스트 세트 2개를 사용하지 않는 이유: 모델 개발할 때 항상 모델 설정을 튜닝하기 때문   \n",
    "정보 누설 때문에 검증 세트의 성능 기반으로 모델 설정 튜닝하면 검증 세트에 과대적합 될 수 있음\n",
    "\n",
    "**단순 홀드아웃 검증**\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/26396102/48557545-6a880f00-e92a-11e8-9ca6-7ff835c278fd.PNG\"/>\n",
    "\n",
    "데이터 적을 때는 검증 세트와 테스트 세트의 샘플이 너무 적어 주어진 전체 데이터를 통계적으로 대표하지 못할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4d782eb2bc7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_validation_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#데이터를 섞는 것이 좋음(셔플링)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum_validation_samples\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#검증 세트를 만듬\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#홀드아웃 검증 구현 예\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_validation_samples = 10000\n",
    "np.random.shuffle(data) #데이터를 섞는 것이 좋음(셔플링)\n",
    "\n",
    "validation_data = data[:num_validation_samples] #검증 세트를 만듬\n",
    "data = data[num_validation_samples:]\n",
    "\n",
    "training_data = data[:] #훈련 세트를 만듬\n",
    "\n",
    "#훈련 세트에서 모델 훈련하고 검증 세트로 평가함\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "#모델 튜닝, 훈련, 평가, 다시 튜닝 ...\n",
    "\n",
    "#하이퍼파라미터 튜닝 끝나면 테스트 데이터 제외한 모든 데이터를 사용해 모델을 다시 훈련시킴\n",
    "model = get_model()\n",
    "model.train(np.concatenate([training_data,\n",
    "                           validation_data]))\n",
    "\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-겹 교차 검증**\n",
    "\n",
    "데이터를 동일한 크기를 가진 K개 분할로 나눔   \n",
    "각 분할 i 에 대해 남은 K-1개의 분할로 모델 훈련하고 분할 i에서 모델 평가함   \n",
    "최종 점수는 K개의 점수의 평균\n",
    "\n",
    "모델의 성능이 데이터의 분할에 따라 편차 클 때 사용\n",
    "\n",
    "<img src=\"https://thebook.io/img/006975/130.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-겹 교차 검증 구현 예\n",
    "\n",
    "k=4\n",
    "num_validation_samples = len(data) #K\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold:\n",
    "                          num_validation_samples * (fold+1)]  #검증 데이터 부분을 선택\n",
    "    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold+1)]  \n",
    "    #남은 데이터를 훈련 데이터로 사용\n",
    "    #리스트에서 + 연산자: 두 리스트를 연결(더하는 것 X)\n",
    "    \n",
    "    model = get_model() #훈련되지 않은 새로운 모델 만듬\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "    \n",
    "validation_score = np.average(validation_scores) #검증 점수: K개 폴드 검증 점수의 평균\n",
    "\n",
    "\n",
    "#테스트 데이터를 제외한 전체 데이터로 최종 모델 훈련시킴\n",
    "model = get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**셔플링을 사용한 반복 K-겹 교차 검증**\n",
    "\n",
    "가용 데이터 적고 가능한 정확하게 모델 평가하고자 할 때 사용\n",
    "\n",
    "K-겹 교차 검증을 여러 번 적용, K개의 분할로 나누기 전 매번 데이터를 무작위로 섞음   \n",
    "P(반복 횟수)\\*K개의 모델을 훈련, 평가해서 비용이 매우 많이 듬\n",
    "\n",
    "#### 4.4.2 기억해야 할 것\n",
    "\n",
    "평가 방식을 선택할 때 유념해야 할 것\n",
    "- 대표성 있는 데이터   \n",
    "        훈련 세트와 테스트 세트로 나누기 전 데이터를 무작위로 섞는 것이 일반적임\n",
    "- 시간의 방향   \n",
    "        과거로부터 미래를 예측하려고 한다면 데이터 분할 전에 무작위로 섞으면 안됨   \n",
    "        훈련 세트에 있는 데이터보다 테스트 세트에 있는 모든 데이터가 미래의 것이어야 함\n",
    "- 데이터 중복   \n",
    "        훈련 세트와 검증 세트가 중복되지 않는지 확인해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 데이터 전처리, 특성 공학, 특성 학습\n",
    "\n",
    "#### 4.3.1 신경망을 위한 데이터 전처리\n",
    "\n",
    "**벡터화**\n",
    "\n",
    "신경망에서 모든 입력과 타깃은 부동 소수 데이터로 이뤄진 텐서여야 함(특정 경우에는 정수)   \n",
    "사운드, 이미지, 텍스트 등 무엇이든지 텐서로 변환해야 함\n",
    "\n",
    "데이터 벡터화 라고함\n",
    "\n",
    "**값 정규화**\n",
    "\n",
    "데이터를 네트워크에 주입하기 전 각 특성을 독립적으로 정규화해 평균이 0이고 표준 편차가 1이 되도록 만듬\n",
    "\n",
    "네트워크를 쉽게 학습하려면 데이터가 \n",
    "- 작은 값을 취해야 함(대부분 값이 0~1 사이)\n",
    "- 균일해야 함(모든 특성이 대체로 비슷한 범위를 가져야 함)\n",
    "\n",
    "엄격한 정규화 방법(필수적이지는 않음)\n",
    "- 각 특성별로 평균 0이 되도록 정규화\n",
    "- 각 특성별로 표준 편차가 1이 되도록 정규화\n",
    "\n",
    "```\n",
    "x -= x.mean(axis=0)  #x가 (샘플, 특성) 크기인 2D 행렬이라고 가정\n",
    "x /= x.std(axis=0)\n",
    "```\n",
    "\n",
    "**누락된 값 다루기**\n",
    "\n",
    "신경망에서 0이 사전에 정의된 의미 있는 값이 아니면 누락된 값을 0으로 입력해도 됨\n",
    "\n",
    "누락된 값이 있는 훈련 샘플을 고의적으로 만들어서 네트워크가 누락된 값을 무시하는 법을 알게 해야 함   \n",
    "훈련 샘플의 일부를 여러 벌 복사해서 테스트 데이터에서 빠질 것 같은 특성을 제거함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 특성 공학\n",
    "\n",
    "모델에 데이터 주입 전에 하드코딩된 변환을 적용해 알고리즘이 더 잘 수행되도록 만들어 줌\n",
    "\n",
    "특성을 더 간단한 방식으로 표현해 문제를 쉽게 만듬(해당 문제를 아주 잘 이해하고 있어야 함)\n",
    "\n",
    "- 좋은 특성은 적은 자원을 사용해 문제를 풀 수 있음\n",
    "- 좋은 특성은 더 적은 데이터로 문제를 풀 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 과대적합과 과소적합\n",
    "\n",
    "최적화: 가능한 훈련 데이터에서 최고의 성능을 얻으려 모델을 조정하는 과정   \n",
    "일반화: 훈련된 모델이 이전에 본 적 없던 데이터에서 얼마나 잘 수행되는지\n",
    "\n",
    "좋은 모델 만드는 목적: 좋은 일반화 성능 얻는 것\n",
    "\n",
    "훈련 데이터 손실 낮아질수록 테스트 데이터 손실 낮아짐   \n",
    "-> 모델이 과소적합(모델 성능이 발전될 여지가 있음)\n",
    "-> 훈련 데이터에 여러 번 반복 학습하면 과대적합됨\n",
    "\n",
    "더 많은 훈련 데이터 모으는 것이 가장 좋음\n",
    "\n",
    "규제: 과대적합 피하는 처리 과정\n",
    "\n",
    "\n",
    "#### 4.4.1 네트워크 크기 축소\n",
    "\n",
    "과대적합 막는 단순한 방법: 모델의 크기(모델에 있는 학습 파라미터의 수)를 줄이는 것   \n",
    "파라미터의 수는 층의 수, 각 층의 유닛 수에 의해 결정됨   \n",
    "모델의 용량: 모델에 있는 학습 파라미터의 수\n",
    "\n",
    "손실 최소화 위해 타깃에 대한 예측 성능을 가진 압축된 표현을 학습해야 함   \n",
    "과소적합되지 않도록 충분한 파라미터 가진 모델 사용해야 함\n",
    "\n",
    "데이터에 알맞은 모델 크기 찾으려면 각기 다른 구조를(검증 세트에서) 평가해 봐야 함\n",
    "\n",
    "\n",
    "#### 4.4.2 가중치 규제 추가\n",
    "\n",
    "오캄의 면도날: 어떤 것에 대한 두 가지의 설명이 있다면 더 적은 가정이 필요한 간단한 설명이 옳을 것   \n",
    "간단한 모델이 복잡한 모델보다 덜 과대적합될 가능성이 높음   \n",
    "    간단한 모델: 파라미터 값 분포의 엔트로피가 작은 모델   \n",
    "\n",
    "가중치 규제: 과대적합 완화 위한 일반적 방법으로 네트워크의 복잡도에 제한을 둬서 가중치가 작은 값을 가지도록 강제하는 것\n",
    "- L1 규제   \n",
    "        가중치의 절댓값에 비례하는 비용이 추가됨(가중치의 L1 노름)\n",
    "- L2 규제(가중치 감쇠)\n",
    "        가중치의 제곱에 비례하는 비용이 추가됨(가중치의 L2 노름)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델에 L2 가중치 규제하기\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16,kernel_regularizer = reqularizers.l2(0.001),\n",
    "                      activation = 'relu', input_shape = (10000,)))\n",
    "#l2: 가중치 행렬의 모든 원소를 제곱하고 0.001을 곱해 네트워크 전체 손실에 더해진다는 의미(페널티 항은 훈련할 때만 추가됨)\n",
    "\n",
    "model. add(layers.Dense(16,kernel_regularizer = regularizers.l2(0.001),\n",
    "                       activation = 'relu'))\n",
    "\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "#케라스에서 사용할 수 있는 가중치 규제\n",
    "\n",
    "regularizers.l1(0.001) #L1 규제\n",
    "reqularizers.l1_l2(l1=0.001, l2=0.001) #L1과 L2 규제 병행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3 드롭아웃 추가\n",
    "\n",
    "신경망을 위해 사용되는 규제 기법 중 가장 효과적이고 널리 사용되는 방법 중 하나   \n",
    "네트워크 층에 드롭아웃 적용하면 훈련 동안 무작위로 층의 일부 출력 특성을 제외시킴(0으로 만듬)   \n",
    "드롭 아웃 비율: 0이 될 특성의 비율(보통 0.2~0.5)   \n",
    "\n",
    "테스트 단계에서는 어떤 유닛도 드롭아웃되지 않음, 층의 출력을 드롭아웃 비율에 비례해 줄여줌(훈련 때보다 더 많은 유닛이 활성화돼서)\n",
    "\n",
    "케라스에서는 층의 출력 바로 뒤에 Dropout 층을 추가해 네트워크에 드롭아웃 적용할 수 있음\n",
    "```\n",
    "model.add(layers.Dropout(0.5))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 보편적인 머신 러닝 작업 흐름\n",
    "\n",
    "#### 4.5.1 문제 정의와 데이터셋 수집\n",
    "\n",
    "- 입력 데이터, 예측하려는 것, 가용한 훈련 데이터의 유무 등\n",
    "- 문제의 종류(이진 분류/ 다중 분류/ 스칼라 회귀/ 벡터 회귀/ 군집/ ...)\n",
    "\n",
    "입,출력이 무엇인지와 어떤 데이터를 사용할 것인지 알아야 다음 단계로 넘어갈 수 있음   \n",
    "이 단계에서 가설을 세워야 함\n",
    "- 주어진 입력으로 출력 예측할 수 있다고 가설을 세움\n",
    "- 가용한 데이터에 입출력 사이 관계를 학습하는 데 충분한 정보가 있다고 가설 세움\n",
    "\n",
    "\n",
    "#### 4.5.2 성공 지표 선택\n",
    "\n",
    "성공의 지표가 모델이 최적화할 손실 함수를 선택하는 기준이 됨\n",
    "\n",
    "클래스 분포가 균일한 분류 문제에서는 정확도와 ROC AUC가 일반적인 지표   \n",
    "클래스 분포가 균이하지 않은 문제에서는 정밀도와 재현율 사용 가능   \n",
    "랭킹 문제나 다중 레이블 문제에는 평균 정밀도 사용 가능\n",
    "\n",
    "\n",
    "#### 4.5.3 평가 방법 선택\n",
    "\n",
    "- 홀드아웃 검증 세트 분리   \n",
    "        데이터가 풍부할 때 사용\n",
    "- K-겹 교차 검증   \n",
    "        홀드아웃 검증을 사용하기에 샘플 수가 너무 적을 때 사용\n",
    "- 반복 K-겹 교차 검증   \n",
    "        데이터가 적고 매우 정확한 모델 평가가 필요할 때 사용\n",
    "        \n",
    "#### 4.5.4 데이터 준비\n",
    "\n",
    "머신 러닝 모델에 주입할 데이터를 구성해야 함\n",
    "\n",
    "ex) 머신 러닝 모델을 심층 신경망이라고 가정\n",
    "- 데이터는 텐서로 구성됨\n",
    "- 텐서에 있는 값은 일반적으로 작은 값으로 스케일 조정되어 있음 ([-1.1] 이나 [0,1] 범위)\n",
    "- 특성마다 범위가 다르면 정규화해야 함\n",
    "- 특성 공학을 수행할 수 있음(특히 데이터가 적을 때)\n",
    "\n",
    "\n",
    "#### 4.5.5 기본보다 나은 모델 훈련하기\n",
    "\n",
    "통계적 검정력 달성하는 것이 목표   \n",
    "아주 단순한 모델보다 나은 수준의 작은 모델 개발\n",
    "\n",
    "ex) MNIST 숫자 이미지 분류 예에서는 0.1보다 높은 정확도 내는 모델이 통계적 검정력 가졌다고 말할 수 있음   \n",
    "ex) IMDB 예에서는 0.5보다 높은 정확도 갖는 것\n",
    "\n",
    "2개의 가설\n",
    "- 주어진 입력으로 출력 예측 가능하다고 가설 세움\n",
    "- 가용 데이터에 입출력 사이의 관계 학습에 충분한 정보가 있다고 가설 세움\n",
    "\n",
    "가설 잘못됐으면 기획부터 다시 해야함\n",
    "\n",
    "잘 진행되면 모델 만들기 위해 중요 선택 해야함\n",
    "- 마지막 층의 활성화 함수   \n",
    "        네트워크의 출력에 필요한 제한 가함   \n",
    "        ex) IMDB 분류 예는 마지막 층에 시그모이드 함수 사용함\n",
    "- 손실 함수\n",
    "        ex) IMDB 예시는 binary_crossentropy 사용, 회귀 예제는 mse 사용\n",
    "- 최적화 설정   \n",
    "        어떤 옵티마이저 사용하는지, 학습률 얼마인지 (대부분 rmsprop, 기본 학습률 사용하는 것이 무난함)\n",
    "\n",
    "\n",
    "**모델에 맞는 마지막 층의 활성화 함수와 손실 함수 선택**\n",
    "\n",
    "| 문제 유형 | 마지막 층의 활성화 함수 | 손실 함수 |\n",
    "| :---: | :---: | :---: |\n",
    "| 이진 분류 | 시그모이드 | binary_crossentropy |\n",
    "| 단일 레이블 다중 분류 | 소프트맥스 | categorical_crossentropy|\n",
    "| 다중 레이블 다중 분류 | 시그모이드 | binary_crossentropy |\n",
    "|임의 값에 대한 회귀 | 없음 | mse |\n",
    "| 0과 1 사이 값에 대한 회귀 | 시그모이드 | mse 또는 binary_crossentropy |\n",
    "\n",
    "#### 4.5.6 몸집 키우기: 과대적합 모델 구축\n",
    "\n",
    "얼마나 큰 모델을 만들어야 하는지 알기 위해서 과대적합된 모델 만들어야 함\n",
    "1. 층을 추가함\n",
    "2. 층의 크기를 키움\n",
    "3. 더 많은 에포크 동안 훈련함\n",
    "\n",
    "훈련, 검증 지표, 훈련 손실, 검증 손실 모니터링   \n",
    "검증 데이터에서 모델 성능이 감소하기 시작했으 때 과대적합에 도달한 것\n",
    "\n",
    "#### 4.5.7 모델 규제와 하이퍼파라미터 튜닝\n",
    "\n",
    "반복적으로 모델 수정, 훈련, 검증 데이터에서 평가(테스트 데이터 사용 X)\n",
    "\n",
    "**적용해 볼 것들**\n",
    "- 드롭아웃을 추가\n",
    "- 층 추가/ 제거 다른 구조 시도\n",
    "- L1, L2 또는 두가지 모두 추가\n",
    "- 최적의 설정 찾기 위해 하이퍼파라미터 바꿔서 시도(층의 유닛 수, 옵티마이저 학습률 등)\n",
    "- 선택적으로 특성 공학 시도(새로운 특성 추가 / 유용하지 않을 것 같은 특성 제거)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
