{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 합성곱 신경망(컨브넷) 소개\n",
    "\n",
    "간단한 컨브넷 예제   \n",
    "기본적인 컨브넷이어도 완전 연결된 모델의 성능을 훨씬 앞지를 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 합성곱 연산\n",
    "\n",
    "Dense 층: 입력 특성 공간에 있는 전역 패턴 학습   \n",
    "합성곱 층: 지역 패턴 학습 (이미지일 때 작은 2D 윈도우로 입력에서 패턴을 찾음)\n",
    "\n",
    "- 학습된 패턴은 평행 이동 불변성을 가짐   \n",
    "        완전 연결 네트워크는 새로운 위치에 나타난 것은 새로운 패턴으로 학습해야 함\n",
    "        컨브넷은 이미지 효율적으로 처리하게 만들어 줌 (적은 수의 훈련 샘플을 사용해서 일반화 능력 가진 표현을 학습 가능함)\n",
    "- 컨브넷은 패턴의 공간적 계층 구조를 학습할 수 있음   \n",
    "        첫 번째 합성곱이 에지 같은 작은 지역 패턴 학습, 두 번째 합성곱 층은 첫 번째 층의 특성으로 구성된 더 큰 패턴 학습   \n",
    "        -> 매우 복잡하고 추상적인 시각적 개념 효과적으로 학습 가능함\n",
    "\n",
    "합성곱 연산은 특성 맵(3D 텐서)에 적용됨   \n",
    "2개의 공간축(높이, 너비), 깊이(채널)축으로 구성됨  (RGB 이미지는 3개의 컬러 채널 -> 축의 차원이 3)   \n",
    "입력 특성 맵에서 작은 패치들 추출, 모든 패치에 같은 변환 적용해 출력 특성 맵을 만듬\n",
    "\n",
    "출력 텐서(높이, 너비 가진 3D 텐서)의 깊이는 층의 매개변수로 결정됨 -> 깊이 축의 채널은 **필터**를 의미함\n",
    "\n",
    "(28, 28, 1) 크기의 특성 맵 입력 -> (26, 26, 32) 크기의 특성 맵 출력   \n",
    "여기서 입력에 대한 32개의 필터를 적용한 것   \n",
    "32개의 출력 채널 각각은 26x26 크기의 배열 값을 가짐 (입력에 대한 필터의 **응답 맵**   \n",
    "\n",
    "\n",
    "합성곱 정의에 필요한 2개의 파라미터\n",
    "- 입력으로부터 뽑아낼 패치의 크기\n",
    "        보통 3x3, 5x5 크기 사용\n",
    "- 특성 맵의 출력 깊이\n",
    "        합성곱으로 계산할 필터 수\n",
    "        \n",
    "```\n",
    "Conv2D(output_depth, (window_height, window_width))\n",
    "```\n",
    "\n",
    "합성곱은 3D 입력 특성 맵 위를 3x3 또는 5x5 크기의 윈도우가 슬라이딩 하면서 모든 위치에서 3D 특성 패치 추출하는 방식으로 작동함   \n",
    "3D 패치는 (output_depth, ) 크기의 1D 벡터로 변환됨 (합성곱 커널 통해 변환)   \n",
    "변환된 모든 벡터는 (height, width, output_depth) 크기의 3D 특성 맵으로 재구성됨   \n",
    "출력 특성 맵의 공간상 위치는 입력 특성 맵의 같은 위치에 대응됨\n",
    "\n",
    "출력 높이와 너비는 입력 높이와 너비와는 다를 수 있음\n",
    "- 경계 문제\n",
    "        입력과 동일한 높이, 너비 가진 출력 특성 맵 얻고 싶으면 패딩 사용할 수 있음\n",
    "        Conv2D 층에서 padding 매개변수로 설정 가능 (기본값은 valid(패딩 사용 x))\n",
    "- 스트라이드 사용 여부에 따라 다름\n",
    "        스트라이드: 두 번의 연속적인 윈도우 사이의 거리\n",
    "        기본값은 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 최대 풀링 연산\n",
    "\n",
    "최대 풀링의 역할: 강제적으로 특성 맵 다운샘플링 하는 것\n",
    "\n",
    "입력 특성 맵에서 윈도우에 맞는 패치 추출하고 각 채널별 최댓값 출력함 (최댓값 추출 연산 사용)   \n",
    "보통 2x2 윈도우와 스트라이드 2를 사용해 특성 맵을 절반 크기로 다운샘플링함\n",
    "\n",
    "다운샘플링하는 이유: 처리할 특성 맵의 가중치 개수 줄이기 위해서   \n",
    "연속적인 합성곱 층이 점점 커진 윈도우 통해 바라보도록 만들어 필터의 공간적 계층 구조 구성함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련하기\n",
    "\n",
    "#### 5.2.1 작은 데이터셋 문제에서 딥러닝의 타당성\n",
    "\n",
    "딥러닝 모델은 조금씩 변경해 다른 문제에 재사용 가능함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2 데이터 내려받기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 고양이 이미지 전체 개수: 1000\n",
      "훈련용 강아지 이미지 전체 개수: 1000\n",
      "검증용 강아지 이미지 전체 개수: 500\n",
      "검증용 강아지 이미지 전체 개수: 500\n",
      "테스트용 강아지 이미지 전체 개수: 500\n",
      "테스트용 강아지 이미지 전체 개수: 500\n"
     ]
    }
   ],
   "source": [
    "#훈련, 검증, 테스트 폴더로 이미지 복사하기\n",
    "\n",
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = './datasets/cats_and_dogs/train' #원본 데이터셋 압축 해제한 디렉터리 경로\n",
    "\n",
    "base_dir= './datasets/cats_and_dogs_small' #소규모 데이터셋 저장할 디렉터리\n",
    "#os.mkdir(base_dir)\n",
    "\n",
    "#훈련, 검증, 테스트 분할 위한 디렉터리\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "#os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "#os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "#os.mkdir(test_dir)\n",
    "\n",
    "#훈련용 고양이, 강아지 사진 디렉터리\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "#os.mkdir(train_cats_dir)\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "#os.mkdir(train_dogs_dir)\n",
    "\n",
    "#검증용 고양이, 강아지 사진 디렉터리\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "#os.mkdir(validation_cats_dir)\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "#os.mkdir(validation_dogs_dir)\n",
    "\n",
    "#테스트용 고양이, 강아지 사진 디렉터리\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "#os.mkdir(test_cats_dir)\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "#os.mkdir(test_dogs_dir)\n",
    "\n",
    "#처음 1000개의 고양이 이미지를 train_cats_dir에 복사\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "#다음 500개의 고양이 이미지를 validation_cats_dir에 복사    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "#다음 500개의 고양이 이미지를 test_cats_dir에 복사\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "#처음 1000개의 강아지 이미지를 train_cats_dir에 복사\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "#다음 500개의 강아지 이미지를 validation_cats_dir에 복사    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "#다음 500개의 강아지 이미지를 test_cats_dir에 복사\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "        \n",
    "        \n",
    "#잘 됐는지 사진 개수 카운트로 확인\n",
    "print('훈련용 고양이 이미지 전체 개수:', len(os.listdir(train_cats_dir)))\n",
    "print('훈련용 강아지 이미지 전체 개수:', len(os.listdir(train_dogs_dir)))\n",
    "\n",
    "print('검증용 강아지 이미지 전체 개수:', len(os.listdir(validation_cats_dir)))\n",
    "print('검증용 강아지 이미지 전체 개수:', len(os.listdir(validation_dogs_dir)))\n",
    "\n",
    "print('테스트용 강아지 이미지 전체 개수:', len(os.listdir(test_cats_dir)))\n",
    "print('테스트용 강아지 이미지 전체 개수:', len(os.listdir(test_dogs_dir)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.3 네트워크 구성하기\n",
    "\n",
    "Conv2D(relu 활성화 함수 사용), MaxPooling2D 층을 번갈아 쌓은 컨브넷 만들기   \n",
    "150x150 크기의 입력으로 시작해서 Flatten 층 이전에 7x7 크기의 특성 맵으로 줄어듬\n",
    "\n",
    "특성 맵의 깊이는 네트워크에서 점진적으로 증가(32 -> 128), 크기는 감소(150x150 -> 7x7)\n",
    "\n",
    "이진 분류 문제라서 네트워크는 하나의 유닛(크기가 1인 Dense 층), sigmoid 활성화 함수로 끝남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#강아지 vs 고양이 분류를 위한 소규모 컨브넷 만들기\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 훈련 설정\n",
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.4 데이터 전처리\n",
    "\n",
    "데이터가 JPEG 파일로 되어있어서 네트워크에 주입하려면 과정이 필요함\n",
    "1. 사진 파일을 읽음\n",
    "2. JPEG 콘텐츠를 RGB 픽셀 값으로 디코딩\n",
    "3. 부동 소수 타입의 텐서로 변환\n",
    "4. 픽셀 값(0~255)의 스케일을 [0,1] 사이로 조정\n",
    "\n",
    "keras.preprocessing.image에 이미지 처리 위한 헬퍼 도구들 있음   \n",
    "ImageDataGenerator 클래스는 디스크에 있는 이미지 파일을 전처리된 배치 텐서로 자동으로 바꿔 주는 파이썬 제너레이터를 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#ImageDataGenerator 사용해 디렉터리에서 이미지 읽기\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#모든 이미지를 1/255로 스케일 조정\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(150,150), #모든 이미지를 150x150 크기로 바꿈\n",
    "                                                   batch_size=20,\n",
    "                                                   class_mode='binary') #binary_crossentropy 손실 사용해서 이진 레이블 필요함\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                       target_size=(150,150),\n",
    "                                                       batch_size=20,\n",
    "                                                       class_mode='binary')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-084ed1e6f3dc>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 41s 406ms/step - loss: 0.6919 - acc: 0.5180 - val_loss: 0.6775 - val_acc: 0.5430\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 44s 439ms/step - loss: 0.6638 - acc: 0.6005 - val_loss: 0.6474 - val_acc: 0.6110\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 48s 478ms/step - loss: 0.6192 - acc: 0.6765 - val_loss: 0.6358 - val_acc: 0.6340\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 47s 466ms/step - loss: 0.5733 - acc: 0.6960 - val_loss: 0.5909 - val_acc: 0.6890\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 46s 457ms/step - loss: 0.5410 - acc: 0.7265 - val_loss: 0.5923 - val_acc: 0.6710\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 45s 448ms/step - loss: 0.5157 - acc: 0.7505 - val_loss: 0.5804 - val_acc: 0.6990\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 45s 454ms/step - loss: 0.4924 - acc: 0.7630 - val_loss: 0.5654 - val_acc: 0.7060\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 45s 449ms/step - loss: 0.4634 - acc: 0.7725 - val_loss: 0.5508 - val_acc: 0.7090\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 45s 452ms/step - loss: 0.4356 - acc: 0.7930 - val_loss: 0.5668 - val_acc: 0.7100\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 45s 451ms/step - loss: 0.4124 - acc: 0.8100 - val_loss: 0.5512 - val_acc: 0.7060\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 43s 435ms/step - loss: 0.3814 - acc: 0.8300 - val_loss: 0.5268 - val_acc: 0.7330\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 43s 432ms/step - loss: 0.3557 - acc: 0.8425 - val_loss: 0.5902 - val_acc: 0.7170\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 45s 447ms/step - loss: 0.3417 - acc: 0.8505 - val_loss: 0.5580 - val_acc: 0.7300\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 44s 435ms/step - loss: 0.3164 - acc: 0.8625 - val_loss: 0.5866 - val_acc: 0.7230\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 43s 426ms/step - loss: 0.2937 - acc: 0.8780 - val_loss: 0.5567 - val_acc: 0.7410\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 42s 423ms/step - loss: 0.2601 - acc: 0.8965 - val_loss: 0.5584 - val_acc: 0.7370\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 43s 428ms/step - loss: 0.2460 - acc: 0.8935 - val_loss: 0.5634 - val_acc: 0.7410\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 44s 443ms/step - loss: 0.2123 - acc: 0.9260 - val_loss: 0.7864 - val_acc: 0.7050\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 43s 433ms/step - loss: 0.2026 - acc: 0.9205 - val_loss: 0.6058 - val_acc: 0.7430\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 43s 429ms/step - loss: 0.1792 - acc: 0.9385 - val_loss: 0.6458 - val_acc: 0.7280\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 42s 425ms/step - loss: 0.1624 - acc: 0.9425 - val_loss: 0.6542 - val_acc: 0.7380\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 42s 424ms/step - loss: 0.1451 - acc: 0.9500 - val_loss: 0.7060 - val_acc: 0.7220\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 42s 424ms/step - loss: 0.1303 - acc: 0.9530 - val_loss: 0.7058 - val_acc: 0.7330\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 42s 423ms/step - loss: 0.1140 - acc: 0.9665 - val_loss: 0.7040 - val_acc: 0.7270\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 42s 423ms/step - loss: 0.0945 - acc: 0.9725 - val_loss: 0.7141 - val_acc: 0.7390\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 43s 430ms/step - loss: 0.0881 - acc: 0.9735 - val_loss: 0.7992 - val_acc: 0.7320\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 42s 425ms/step - loss: 0.0769 - acc: 0.9775 - val_loss: 0.7762 - val_acc: 0.7280\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 44s 440ms/step - loss: 0.0579 - acc: 0.9830 - val_loss: 0.8425 - val_acc: 0.7390\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 44s 440ms/step - loss: 0.0591 - acc: 0.9860 - val_loss: 1.1920 - val_acc: 0.6990\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 43s 426ms/step - loss: 0.0435 - acc: 0.9890 - val_loss: 0.9577 - val_acc: 0.7310\n"
     ]
    }
   ],
   "source": [
    "#배치 제너레이터 사용해 모델 훈련\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=100,\n",
    "                             epochs=30,\n",
    "                             validation_data = validation_generator,\n",
    "                             validation_steps=50)\n",
    "\n",
    "#모델 저장\n",
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#훈련의 정확도와 손실 그래프 그리기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#과대적합의 특성 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.5 데이터 증식 사용하기\n",
    "\n",
    "기존 훈련 샘플로부터 더 많은 훈련 데이터 생성하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataCenerator 사용해 데이터 증식 설정하기\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=20, #랜덤하게 사진 회전시킬 각도 범위(0~180)\n",
    "                            width_shift_range=0.1, #사진을 수평/수직으로 랜덤하게 평행 이동시킬 범위(전체 높이,너비에 대한 비율)\n",
    "                            height_shift_range=0.1,\n",
    "                            shear_range=0.1, #랜덤하게 전단 변환 적용할 각도 범위\n",
    "                            zoom_range=0.1, #랜덤하게 사진 확대할 범위\n",
    "                            horizontal_flip=True, #랜덤하게 이미지 수평 뒤집기\n",
    "                            fill_mode='nearest') #회전, 가로/세로 이동으로 인해 새롭게 생성해야 할 픽셀 채울 전략"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#드롭아웃을 포함한 새로운 컨브넷 정의하기\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 증식 제너레이터 사용해 컨브넷 훈련하기\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  rotation_range=40,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255) #검증데이터는 증식되면 안됨\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(150,150),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                       target_size=(150,150),\n",
    "                                                       batch_size=32,\n",
    "                                                       class_mode='binary')\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=100,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)\n",
    "\n",
    "#모델 저장\n",
    "model.save('cats_and_dogs_small_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 사전 훈련된 컨브넷 사용하기\n",
    "\n",
    "대규모 이미지 분류 문제 위해 대량의 데이터셋에서 미리 훈련되어 저장된 네트워크\n",
    "\n",
    "사전 훈련된 네트워크 사용하는 방법\n",
    "1. 특성 추출\n",
    "2. 미세 조정\n",
    "\n",
    "\n",
    "#### 5.3.1 특성 추출\n",
    "\n",
    "사전에 학습된 네트워크 표현 사용해 새로운 샘플에서 흥미로운 특성 뽑아내는 것   \n",
    "특성 사용해 새로운 분류기 처음부터 훈련\n",
    "\n",
    "연속된 합성곱, 풀링 층으로 시작해 완전 연결 분류기로 끝남\n",
    "\n",
    "합성곱 층만 재사용, 완전 연결 분류기는 일반적으로 재사용 X\n",
    "\n",
    "특성 합성곱 층에서 추출한 표현의 일반성(과 재사용성) 수준은 모델에 있는 층의 깊이에 달려 있음   \n",
    "모델의 하위 층은 (에지, 색, 질감 등) 지역적, 매우 일반적 특성 맵 추출함   \n",
    "상위 층은 ('강아지 눈', '고양이 귀' 등) 추상적인 개념 추출   \n",
    "-> 모델의 하위 층 몇 개만 특성 추출에 사용하는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16 합성곱 기반 층 만들기\n",
    "\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', #모델 초기화할 가중치 체크포인트 지정\n",
    "                 include_top=False, #네트워크 최상위 완전 연결 분류기 포함 여부 지정(기본값은 포함)\n",
    "                 input_shape=(150,150,3)) #네트워크에 주입할 이미지 텐서의 크기, 선택 사항(지정 안하면 어떤 크기의 입력도 처리 가능)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 증식 사용하지 않는 빠른 특성 추출**   \n",
    "\n",
    "빠르고 비용 적게 듬, 데이터 증식 사용 불가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사전 훈련된 합성곱 기반 층 사용한 특성 추출하기\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = './datasets/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape =(sample_count, 4,4,512))\n",
    "    labels=np.zeros(shape=(sample_count))\n",
    "    generator=datagen.flow_from_directory(directory,\n",
    "                                         target_size=(150,150),\n",
    "                                         batch_size=batch_size,\n",
    "                                         class_mode='binary')\n",
    "    i=0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i*batch_size : (i+1) * batch_size] = features_batch\n",
    "        labels[i*batch_size : (i+1) * batch_size] = labels_batch\n",
    "        i+=1\n",
    "        if i * batch_size >=sample_count:\n",
    "            break\n",
    "            #제너레이터는 루프 안에서 무한하게 데이터 만들어 내서 모든 이미지 한 번씩 처리 후에는 중지함\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)\n",
    "\n",
    "#추출된 특성의 크기는 (samples, 4, 4, 512)\n",
    "#완전 연결 분ㄹ기에 주입하기 위해 먼저 (samples, 8192) 크기로 펼침\n",
    "\n",
    "train_features = np.reshape(train_features, (2000, 4*4*512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4*4*512))\n",
    "test_features = np.reshape(test_features, (1000, 4*4*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#완전 연결 분류기를 정의하고 훈련하기\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation ='relu', input_dim = 4*4*512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=2e-5),\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                   epochs = 30,\n",
    "                   batch_size=20,\n",
    "                   validation_data = (validation_features, validation_labels))\n",
    "\n",
    "#2개의 Dense 층만 처리하면 돼서 훈련이 매우 빠름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 증식을 사용한 특성 추출**\n",
    "\n",
    "훨씬 느리고 비용 많이 들지만 훈련하는 동안 데이터 증식 기법 사용 가능   \n",
    "conv_base 모델 확정, 입력 데이터 사용해 엔드-투-엔드로 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#합성곱 기반 층 위에 완전 연결 분류기 추가하기\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 컴파일하고 훈련 전에 합성곱 기반 층 **동결**하는 것이 아주 중요   \n",
    "하나 이상의 층 **동결** 한다는 것: 훈련하는 동안 가중치 업데이트되지 않도록 막는다는 뜻\n",
    "\n",
    "케라스에서는 trainable 속성을 False로 설정해 네트워크 동결 가능함\n",
    "\n",
    "컴파일 단계 후에 trainable 속성 변경하면 반드시 모델 다시 컴파일해야함 (안하면 변경 사항 적용 x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#합성곱 기반 층 위에 완전 연결 분류기 추가하기\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "conv_base.trainable = False\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#동결된 합성곱 기반 층과 함께 모델을 엔드-투-엔드로 훈련하기\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# 검증 데이터는 증식되어서는 안 됩니다!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 타깃 디렉터리\n",
    "        train_dir,\n",
    "        # 모든 이미지의 크기를 150 × 150로 변경합니다\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # binary_crossentropy 손실을 사용하므로 이진 레이블이 필요합니다\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2 미세 조정\n",
    "\n",
    "미세 조정: 특성 추출에 사용했던 동결 모델의 상위 층 몇 개를 동결에서 해체하고 모델에 새로 추가한 층과 함께 훈련하는 것\n",
    "\n",
    "네트워크를 미세 조정하는 단계\n",
    "1. 사전 훈련된 기반 네트워크 위에 새로운 네트워크 추가\n",
    "2. 기반 네트워크 동결\n",
    "3. 새로 추가한 네트워크 훈련\n",
    "4. 기반 네트워크에서 일부 층의 동결 해제\n",
    "5. 동결 해제한 층과 새로 추가한 층 함께 훈련\n",
    "\n",
    "1~3단계는 특성 추출 할 때 이미 완료함\n",
    "\n",
    "고려 사항\n",
    "- 하위 층으로 갈수록 미세 조정에 대한 효과가 감소함   \n",
    "        합성곱 기반 층에 있는 하위 층들은 더 일반적이고 재사용 가능한 특성들 인코딩 / 사우이 층은 더 특화된 특성 인코딩\n",
    "- 훈련해야 할 파라미터가 많을수록 과대적합 위험이 커짐        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정 층까지 모든 층 동결하기\n",
    "\n",
    "conv_base.trainable=True\n",
    "\n",
    "set_trainable=False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable=True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 미세 조정하기\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "             metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=100,\n",
    "                             epochs=100,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 데이터에서 모델 평가\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                 target_size(150,150),\n",
    "                                                 batch_size=20,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n",
    "print('test acc: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 컨브넷 학습 시각화\n",
    "\n",
    "컨브넷의 표현은 시각적인 개념을 학습한 것이어서 시각화하기 아주 좋음   \n",
    "\n",
    "세 가지 기법\n",
    "- 컨브넷 중간층의 출력(중간층에 있는 활성화)을 시각화하기   \n",
    "        연속된 컨브넷 층이 입력 어떻게 변형시키는지 이해, 개별적 컨브넷 필터의 의미 파악에 도움이 됨\n",
    "- 컨브넷 필터를 시각화하기\n",
    "        컨브넷의 필터가 찾으려는 시각적 패턴과 개념 무엇인지 상세하게 이해하는 데 도움이 됨\n",
    "- 클래스 활성화에 대한 히트맵을 이미지에 시각화\n",
    "        이미지의 어느 부분이 주어진 클래스에 속하는 데 기여했는지 이해, 이미지에서 객체 위치 추정에 도움이 됨\n",
    "        \n",
    "\n",
    "#### 5.4.1 중간층의 활성화 시각화하기\n",
    "\n",
    "어떤 입력 주어졌을 때 네트워크에 있는 여러 합성곱과 풀링 층이 출력하는 특성 맵 그리는 것   \n",
    "층의 출력이 활성화 함수의 출력이라 종종 **활성화**라고 부름\n",
    "\n",
    "너비, 높이, 깊이(채널) 3개의 차원에 대해 특성 맵을 시각화하는 것이 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2절에서 저장했던 모델 로드해서 시작\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('cats_and_dogs_small_2.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#개별 이미지 전처리하기\n",
    "\n",
    "img_path = './datasets/cats_and_dogs_small/test/cats/cat.1700.jpg'\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150,150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0) #이미지를 4D 텐서로 변경\n",
    "img_tensor /= 255. #모델이 훈련될 때 입력에 적용한 전처리 방식을 동일하게 사용\n",
    "\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트 사진 출력하기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 배치를 입력받아 모든 합성곱과 풀링 층의 활성화를 출력하는 케라스 모델 만들 것   \n",
    "케라스의 Model 클래스를 사용   \n",
    "입력 텐서, 출력 텐서 2개의 매개변수가 필요함   \n",
    "Model 클래스를 사용하면 Sequential과는 달리 여러 개의 출력 가진 모델 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력 텐서와 출력 텐서의 리스트로 모델 객체 만들기\n",
    "\n",
    "from keras import models\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers[:8]] #상위 8개 층의 출력을 추출\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outptus) #입력에 대해 8개 층의 출력 반환하는 모델\n",
    "\n",
    "#하나의 입력과 층의 활성화마다 하나씩 총 8개의 출력을 가짐\n",
    "\n",
    "#예측 모드로 모델 실행\n",
    "activations = activation_model.predict(img_tensor) #층의 활성화마다 하나씩 8개의 넘파이 배열로 이루어진 리스트 반환\n",
    "\n",
    "#32개의 채널 가진 148x148 크기의 특성 맵\n",
    "#원본 모델의 첫 번째 층 활성화 중 20번째 채널 시각화하기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(first_layer_activation[0,:,:,19], cmap='viridis')\n",
    "#대각선 에지 감지하도록 인코딩된 것 같음\n",
    "\n",
    "#16번째 채널 시각화\n",
    "plt.matshow(first_layer_activation[0,:,:,15], cmap='viridis')\n",
    "#밝은 녹색 점 감지하도록 인코딩된 것 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#중간층의 모든 활성화에 있는 채널 시각화하기\n",
    "\n",
    "layer_names=[]\n",
    "for layer in model.layers[:8]:\n",
    "    layer_names.append(layer.name) #층의 이름을 그래프 제목으로 사용\n",
    "    \n",
    "images_per_row =16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations): #특성 맵을 그림\n",
    "    n_features = layer_activation.shape[-1] #특정 맵에 있는 특성의 수\n",
    "    \n",
    "    size = layer_activation.shape[1] #특성 맵의 크기는 (1, size, size, n_features)\n",
    "    \n",
    "    n_cols = n_features // images_per_row #활성화 채널 위한 그리드 크기 구함\n",
    "    display_grid = np.zeros((size*n_cols, images_per_row * size))\n",
    "    \n",
    "    for col in range(n_cols): #각 활성화를 하나의 큰 그리드에 채움\n",
    "        for row in range(images_per_row):\n",
    "            channel_iamge = layer_activation[0, :,:, col*images_per_row+row]\n",
    "            channel_imgae -= channel_image.mean() #그래프로 나타내기 좋게 특성을 처리함\n",
    "            channel_image *=64\n",
    "            channel_image +=128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            display_grid[col*size : (col+1) *size,\n",
    "                        row*size : (row+1) * size] = channel)image #그리드를 출력함\n",
    "            \n",
    "        scale = 1./size\n",
    "        plt.figure(figsize=(scale*display_grid.shape[1],\n",
    "                           scale *display_grid.shape[0]))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect = 'auto', cmap='viridis')\n",
    "\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫 번째 층은 여러 종류의 에지 감지기 모아 놓은 것 같음\n",
    "        이 단계의 활성화에는 초기 사진에 있는 거의 모든 정보가 유지됨\n",
    "- 상위 층으로 갈수록 활성화는 점점 더 추상적으로 되고 시각적으로 이해하기 어려워짐\n",
    "        고수준 개념(고양이 귀) 인코딩하기 시작함    \n",
    "        이미지 클래스에 관한 정보가 증가함\n",
    "- 비어 있는 활성화가 층이 깊어짐에 따라 늘어남\n",
    "        층을 올라가면서 활성화되지 않는 필터들이 생김   \n",
    "        필터에 인코딩된 패턴이 입력 이미지에 나타나지 않았다는 것을 의미함\n",
    "        \n",
    "심층 신경망은 입력되는 원본 데이터에 대한 정보 정제 파이프라인처럼 작동함   \n",
    "반복적인 변환을 통해 관계없는 정보를 걸러 내고 유용한 정보는 강조되고 개선됨 ( 여기에서는 이미지의 클래스 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2 컨브넷 필터 시각화하기\n",
    "\n",
    "각 필터가 반응하는 시각적 패턴 그려보기   \n",
    "빈 입력 이미지에서 시작해 특정 필터의 응답 최대화하기 위해 컨브넷 입력 이미지에 경사 상승법을 적용함\n",
    "\n",
    "전체 과정\n",
    "- 특정 합성곱 층의 한 필터 값을 최대화하는 손실 함수 정의\n",
    "- 활성화 값 최대화하기 위해 입력 이미지 변경하도록 확률적 경사 상승법 사용\n",
    "        경사 상승법 구현 위해 모델의 입력에 대한 손실의 그래디언트가 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필터 시각화를 위한 손실 텐서 정의\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras import backend as K\n",
    "\n",
    "model = VGG16(weights = 'imagenet',\n",
    "             include_top = False)\n",
    "\n",
    "layer_name = 'block3_conv1'\n",
    "filter_index = 0\n",
    "\n",
    "layer_output = model.get_layer(layer_name).output\n",
    "loss = K.mean(layer_output[:,:,:,filter_index])\n",
    "\n",
    "#입력에 대한 손실의 그래디언트 구하기\n",
    "grads = K.gradients(loss, model.input)[0] #gradient 함수가 반환하는 텐서 리스트에서 첫 번째 텐서를 추출함\n",
    "                                          #여기서는 크기가 1인 리스트\n",
    "    \n",
    "#경사 상승법 과정 부드럽게 하기 위해 사용하는 기법\n",
    "#그래디언트 텐서를 L2 노름(텐서에 있는 값을 제곱한 합의 제곱근)으로 나눠 정규화하는 것\n",
    "#입력 이미지에 적용할 수정량 크기를 항상 일정 범위\n",
    "\n",
    "\n",
    "#그래디언트 정규화하기\n",
    "grads /= (K.sqrt(K.mean(K.square(grads)))+1e-5) #0 나눗셈 방지 위해 1e-5를 더함\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주어진 입력 이미지에 대한 손실 텐서와 그래디언트 텐서 계산하기\n",
    "\n",
    "#입력 값에 대한 넘파이 출력 값 추출하기\n",
    "\n",
    "iterate = K.function([model.input], [loss, grads])\n",
    "#넘파이 텐서(크기 1인 텐서의 리스트)를 입력으로 받아 손실과 그래디언트 2개의 넘파이 텐서를 반환함\n",
    "\n",
    "import numpy as np\n",
    "loss_value, grads_value = iterate([np.zeros((1,150,150,3))])\n",
    "\n",
    "#파이썬 루프를 만들어 확률적 경사 상승법 구성\n",
    "\n",
    "input_img_data = np.random.random((1,150,150,3)) * 20 + 128.  #잡음 섞인 회색 이미지로 시작\n",
    "\n",
    "step = 1. #업데이트할 그래디언트의 크기\n",
    "#경사상승법 40회 실행\n",
    "for i in range(40):\n",
    "    loss_value, grads_value = iterate([input_img_data]) #손실과 그래디언트를 계산\n",
    "    input_img_data += grads_value*step #손실 최대화하는 방향으로 입력 이미지를 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텐서를 이미지 형태로 변환하기 위한 유틸리티 함수\n",
    "\n",
    "def deprocess_image(x):\n",
    "    #텐서의 평균이 0, 표준 편차가 0.1이 되도록 정규화\n",
    "    x-= x.mean()\n",
    "    x/= (x.std() + 1e-5)\n",
    "    x*= 0.1\n",
    "    \n",
    "    #[0,1]로 클리핑함\n",
    "    x+= 0.5\n",
    "    x = np.clip(x,0,1)\n",
    "    \n",
    "    #RGB 배열로 변환\n",
    "    x*=255\n",
    "    x=np.clip(x,0,255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필터 시각화 이미지를 만드는 함수\n",
    "#층의 이름, 필터 번호를 입력으로 받아 필터 활성화를 최대화하는 패턴을 이미지 텐서로 출력함\n",
    "\n",
    "def generate_pattern(layer_name, filter_index, size=150):\n",
    "    #주어진 층과 필터의 활성화를 최대화하기 위한 손실 함수를 정의함\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:,:,:,filter_index])\n",
    "    \n",
    "    grads = K.gradients(loss, model.input)[0] #손실에 대한 입력 이미지의 그래디언트 계산\n",
    "    \n",
    "    grads/= (K.sqrt(K.mean(K.square(grads)))+1e-5) #그래디언트 정규화\n",
    "    \n",
    "    iterate = K.function([model.input],[loss,grads]) #입력 이미지에 대한 손실, 그래디언트 반환\n",
    "    \n",
    "    input_img_data = np.random.random((1,size,size,3))*20+128 #잡음 섞인 회색 이미지로 시작\n",
    "    \n",
    "    step = 1.\n",
    "    #경사 상승법을 40단계 실행\n",
    "    for i in range(40):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data +=grads_value * step\n",
    "        \n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(generate_pattern('block3_con1',0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#층에 있는 각 필터에 반응하는 패턴 생성하기\n",
    "\n",
    "layer_name = 'block_conv1'\n",
    "size = 64\n",
    "margin = 5\n",
    "\n",
    "results = np.zeros((8*size+7*margin, 8*size+margin, 3), dtype = 'uint8') #결과를 담을 빈(검은) 이미지\n",
    "\n",
    "for i in range(8): #result 그리드의 행 반복\n",
    "    for j in range(8): #result 그리드의 열 반복\n",
    "        filter_img = generate_pattern(layer_name, i+(J*8), size=size) #layer_name에 있는 i+(j*8)번째 필터에 대한 패턴 생성\n",
    "        #results 그리드의 (i,j)번째 위치에 저장\n",
    "        horizontal_start = i*size+i*margin\n",
    "        horizontal_end = horizontal_start + size\n",
    "        vertical_start = j*size+J*margin\n",
    "        vertical_end = vertical_start+size\n",
    "        results[horizontal_start: horizontal_end, vertical_start: vertical_end, :] = filter_img\n",
    "        \n",
    "#result 그리드를 그림        \n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컨브넷 필터들은 모델의 상위 층으로 갈수록 점점 더 복잡해지고 개선됨\n",
    "- 모델에 있는 첫 번째 층(block1_conv1)의 필터는 간단한 대각선 방향의 에지와 색 인코딩함\n",
    "- block2_conv1의 필터는 에지나 색깔의 조합으로 만들어진 간단한 질감 인코딩함\n",
    "- 더 상위 층의 필터는 깃털, 눈, 나뭇잎 등 자연적인 이미지에서 찾을 수 있는 질감 닮아 가기 시작함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.3 클래스 활성화의 히트맵 시각화하기\n",
    "\n",
    "클래스 활성화 맵(Class Activation Map, CAM) 시각화\n",
    "- 이미지의 어느 부분이 컨브넷의 최종 분류 결정에 기여하는지 이해하는 데에 유용함\n",
    "- 분류에 실수가 있는 경우 컨브넷 결정 과정을 디버깅 하는 데 도움이 됨\n",
    "- 이미지에 특정 물체가 있는 위치를 파악하는 데 사용할 수도 있음\n",
    "\n",
    "입력 이미지에 대한 클래스 활성화의 히트맵을 만듬   \n",
    "클래스 활성화 히트맵은 특정 출력 클래스에 대해 입력 이미지의 모든 위치 계산한 2D 점수 그리드\n",
    "\n",
    "구현하는 방법\n",
    "1. 입력 이미지 주어지면 합성곱 층에 있는 특성 맵의 출력 추출\n",
    "2. 특성 맵의 모든 채널 출력에 채널에 대한 클래스의 그래디언트 평균을 곱함   \n",
    "        '입력 이미지가 각 채널을 활성화하는 정도'에 대한 공간적인 맵을 '클래스에 대한 각 채널의 중요도'로 가중치를 부여해 \n",
    "        '입력 이미지가 클래스를 활성화하는 정도'에 대한 공간적인 맵 만드는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사전 훈련된 가중치로 VGG16 네트워크 로드하기\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16(weights = 'imagenet') #이전 모든 예제에서는 최상단의 완전연결분류기 제외했지만 여기서는 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16을 위해 입력 이미지 전처리하기\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "imp_path = './datasets/creative_commons_elephant.jpg' #이미지 경로\n",
    "\n",
    "img = image.load_img(img_path, target_size=(224,224)) #224x224 크기의 파이썬 이미징 라이브러리(PIL) 객체로 반환됨\n",
    "\n",
    "x = image.img_to_array(img) #(224,224,3) 크기의 넘파이 float32 배열\n",
    "x = np.expand_dims(x,axis=0) #차원을 추가해 (1,224,224,3) 크기의 배치로 배열 변환함\n",
    "\n",
    "x = preprocess_input(x) #데이터를 전처리함(채널별 컬러 정규화를 수행함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이 이미지에서 사전 훈련된 네트워크 실행하고 예측 벡터 이해하기 쉽게 디코딩함\n",
    "\n",
    "preds = model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지에 대한 상위 3개의 예측 클래스\n",
    "- 아프리카 코끼리(92.5% 확률)\n",
    "- 코끼리(7% 확률)\n",
    "- 인도 코끼리(0.4% 확률)\n",
    "\n",
    "예측 벡터에서 최대 활성화된 항목은 '아프리카 코끼리' 클래스에 대한 것으로 386번 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지에서 가장 아프리카 코끼리 같은 부위 시각화 위해 Grad-CAM 처리 과정 구현\n",
    "#Grad-CAM 알고리즘 설정하기\n",
    "\n",
    "african_elephant_output = model.output[:,386] #예측 벡터의 '아프리카 코끼리' 항목\n",
    "\n",
    "last_conv_layer = model.get_layer('block5_conv3') #VGG16의 마지막 합성곱 층인 block5_conv3 층의 특성 맵\n",
    "\n",
    "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0] \n",
    "#block5_conv3의 특정 맵 출력에 대한 '아프리카 코끼리' 클래스의 그래디언트\n",
    "\n",
    "pooled_grads = K.maen(grads, axis=(0,1,2)) #특성 맵 채널별 그래디언트 평균값 담긴 (512, ) 크기의 벡터\n",
    "\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "#샘플 이미지 주어졌을 때 방금 전 정의한 pooled_grads와 block5_conv3의 특성 맵 출력을 구함\n",
    "\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "#두 마리 코끼리가 있는 샘플 이미지 주입하고 2개의 넘파이 배열 얻음\n",
    "\n",
    "#아프리카 코끼리 클래스에 대한 '채널의 중요도'를 특성 맵 배열의 채널에 곱함\n",
    "for i in range(512):\n",
    "    conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
    "    \n",
    "heatmap = np.mean(conv_layer_output_value, axis =-1) #만들어진 특성 맵에서 채널 축 따라 평균한 값이 클래스 활성화의 히트맵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#히트맵 후처리하기 (0과 1 사이로 정규화)\n",
    "\n",
    "heatmap=np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원본 이미지에 히트맵 덧붙이기(OpenCV 사용해서)\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(img_path) #cv2 모듈 사용해 원본 이미지 로드\n",
    "\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0])) #heatmap을 원본 이미지 크기에 맞게 변경함\n",
    "heatmap = np.uint8(255*heatmap) #heatmap을 RGB 포맷으로 변환함\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) #히트맵으로 변환함\n",
    "\n",
    "superimposed_img = heatmap * 0.4 + img #0.4는 히트맵의 강도\n",
    "\n",
    "cv2.imwrite('./datesets/elephant_cam.jpg', superimposed_img) #디스크에 이미지 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시각화 기법이 주는 답\n",
    "- 왜 네터워크가 이 이미지에 아프리카 코끼리가 있다고 생각?\n",
    "- 아프리카 코끼리가 사진 어디에 있는가?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
