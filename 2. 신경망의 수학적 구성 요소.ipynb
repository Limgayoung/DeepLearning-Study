{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 신경망의 수학적 구성 요소\n",
    "\n",
    "## 2.1 신경망과의 첫 만남\n",
    "\n",
    "#### 흑백 손글자 이미지를 10개의 범주로 분류하는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MNIST 데이터셋을 불러와서 훈련 세트와 테스트 세트 만들고 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() #훈련 세트, 테스트 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape #훈련 데이터, 테스트 데이터 확인하기\n",
    "len(train_labels)\n",
    "train_labels\n",
    "\n",
    "test_images.shape\n",
    "len(test_labels)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "#신경망 층 2개\n",
    "network.add(layers.Dense(512,activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10,activation='softmax')) #확률 점수가 들어있는 배열 반환하는 소프트맥스 층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 컴파일 단계\n",
    "\n",
    "> 손실 함수(신경망 성능 측정하는 방법)   \n",
    "옵티마이저(네트워크 업데이트)   \n",
    "훈련과 테스트 과정 모니터링할 지표(지금은 정확도만 고려)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#컴파일\n",
    "#옵티마이저, 손실함수, 지표(지금은 정확도만 고려)\n",
    "network.compile(optimizer = 'rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이미지 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0~255 사이의 값인 uint8 타입의 (60000,28,28) 크기 가진 배열 -> 0~1 사이 값 가지는 float32 타입의 (60000,28*28) 크기 배열\n",
    "train_imgaes = train_images.reshape((60000,28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images=test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 레이블 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#to_categorical: 입력받은 1차원 정수 배열 -> 2차원 배열로 변경\n",
    "train_labels=to_categorical(train_labels)\n",
    "test_labels=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [None, 28, 28]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3413c5b75bc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 697\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:789 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:747 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:976 __call__\n        self.name)\n    C:\\Users\\lim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 784 but received input with shape [None, 28, 28]\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 905us/step - loss: 2.3496 - accuracy: 0.0974\n",
      "test_acc: 0.09740000218153\n"
     ]
    }
   ],
   "source": [
    "#테스트\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 신경망을 위한 데이터 표현\n",
    "텐서: 데이터를 위한 컨테이너   \n",
    "      임의의 차원 개수를 가지는 행렬의 일반화된 모습(텐서에서는 차원을 축이라고도 함)\n",
    "\n",
    "#### 2.2.1 스칼라(0D 텐서)\n",
    "\n",
    "스칼라: 하나의 숫자만 담고 있는 텐서   \n",
    "        넘파이에서는 float32나 float 64 타입의 숫자   \n",
    "\n",
    "\n",
    "ndim 속성으로 넘파이 배열의 축 개수 확인 가능    \n",
    "스칼라 텐서의 축 개수는 0   \n",
    "\n",
    "랭크: 텐서의 축 개수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.array(12)\n",
    "print(x)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 벡터(1D 텐서)\n",
    "\n",
    "벡터: 숫자의 배열\n",
    "      하나의 축을 가짐\n",
    "      \n",
    "      5D 벡터: 하나의 축을 따라 5개의 차원 가진 것\n",
    "      5D 텐서: 5개의 축을 가진 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([12,3,6,14,7]) #5D 벡터(5차원 벡터)\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 행렬(2D 텐서)\n",
    "\n",
    "행렬: 벡터의 배열\n",
    "      2개의 축이 있음(행(가로), 렬(세로))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[5,78,2,34,0],\n",
    "           [6,79,3,35,1],\n",
    "           [7,80,4,36,2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 3D 텐서와 고차원 텐서\n",
    "\n",
    "3D 텐서: 행렬들을 하나의 새로운 배열로 합친 것(직육면체 형태)\n",
    "\n",
    "        3D 텐서들 하나의 배열로 합치면 4D 텐서   \n",
    "        딥러닝에서는 보통 0~4D까지 다룸\n",
    "        영상 데이터 다룰 때는 5D까지 가기도 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[[5,78,2,34,0],\n",
    "           [6,79,3,35,1],\n",
    "           [7,80,4,36,2]],\n",
    "            [[5,78,2,34,0],\n",
    "           [6,79,3,35,1],\n",
    "           [7,80,4,36,2]],\n",
    "            [[5,78,2,34,0],\n",
    "           [6,79,3,35,1],\n",
    "           [7,80,4,36,2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 핵심 속성\n",
    "\n",
    "* 축의 개수(랭크)\n",
    "* 크기\n",
    "    파이썬의 튜플   \n",
    "        행렬의 크기: (3,5)   \n",
    "        3D 텐서의 크기: (3,3,5)   \n",
    "        벡터의 크기: (5,)   \n",
    "        스칼라의 크기: ()\n",
    "* 데이터 타입(넘파이에서는 dtype에 저장됨)   \n",
    "        텐서에 포함된 데이터의 타입   \n",
    "        넘파이 배열은 가변 길이의 문자열 지원 X (텐서는 사전에 할당되어 연속된 메모리에 저장되어야 해서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() #훈련 세트, 테스트 세트\n",
    "\n",
    "print(train_images.ndim) #축의 개수 확인\n",
    "print(train_images.shape) #배열의 크기 확인\n",
    "print(train_images.dtype) #테이터 타입 확인\n",
    "\n",
    "#8비트 정수형 3D 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#다섯번째 이미지 출력\n",
    "\n",
    "digit=train_images[4]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6 넘파이로 텐서 조작하기\n",
    "\n",
    "슬라이싱: 배열에 있는 특정 원소들 선택하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n",
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#11~101번까지 (101번은 포함 X) 숫자 선택해 (90,28,28) 크기의 배열 만듬\n",
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)\n",
    "\n",
    "#동일한데 더 자세한 표기법\n",
    "#각 배열의 축을 따라서 슬라이싱의 시작과 끝 인덱스 지정\n",
    "#:은 전체 인덱스 선택\n",
    "\n",
    "my_slicee=train_images[10:100,:,:]\n",
    "print(my_slicee.shape)\n",
    "\n",
    "my_sliceee=train_images[10:100,0:28,0:28]\n",
    "print(my_sliceee.shape)\n",
    "\n",
    "#오늘쪽 아래 14*14 픽셀 선택\n",
    "my_slice=train_images[:,14:,14:]\n",
    "\n",
    "#음수 인덱스\n",
    "#현재 축의 끝에서 상대적인 위치 나타냄\n",
    "#정중앙에 위치한 14*14 픽셀 조각 잘라내기\n",
    "\n",
    "my_slice=train_images[:,7:-7,7:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.7 배치 데이터\n",
    "\n",
    "샘플 축: 딥러닝에서 사용하는 모든 데이터 텐서의 첫 번째 축 (샘플 차원)   \n",
    "\n",
    "딥러닝 모델은 데이터를 작은 배치로 나눠서 데이터셋을 처리함\n",
    "\n",
    "* MNIST에서 크기가 128인 배치 하나   \n",
    "```\n",
    "batch=train_images[:128]\n",
    "```\n",
    "* 그 다음 배치\n",
    "```\n",
    "batch=train_images[128:256]\n",
    "```\n",
    "* n번째 배치\n",
    "```\n",
    "batch=train_images[128*n:128*(n+1)]\n",
    "```\n",
    "\n",
    "첫번째 축(0번 축)을 **배치 축** 또는 **배치 차원**이라고 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.8 텐서의 실제 사례\n",
    "\n",
    "* 벡터 데이터   \n",
    "    (smaples, features) 크기의 2D 텐서\n",
    "* 시계열 데이터 또는 시퀀스 데이터   \n",
    "    (samples, timesteps, features) 크기의 3D 텐서\n",
    "* 이미지   \n",
    "    (samples, height, width, channels) 또는 (samples, channels, height, width) 크기의 4D 텐서\n",
    "* 동영상   \n",
    "    (samples, frames, height, width, channels) 또는 (samples, frames, channels, height, width) 크기의 5D 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.9 벡터 데이터\n",
    "\n",
    "대부분의 경우에 해당됨   \n",
    "하나의 데이터 포인트가 벡터로 인코딩될 수 있음   \n",
    "배치 데이터는 2D 텐서로 인코딩될 것(벡터의 배열)   \n",
    "첫 번째 축은 **샘플 축**, 두 번째 축은 **특성 축**   \n",
    "\n",
    "    ex) 사람의 나이, 우편번호, 소득으로 구성된 인구 통계 데이터.\n",
    "        10만 명이 포함된 전체 데이터셋은 (100000,3) 크기의 텐서에 저장될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.10 시계열 데이터 또는 시퀀스 데이터\n",
    "\n",
    "데이터에서 시간이 중요할 때에는 시간 축을 포함해 3D 텐서로 저장됨   \n",
    "시간 축은 항상 두 번째 축(인덱스가 1인 축)   \n",
    "<img src=\"https://thebook.io/img/006975/068.jpg\" width=\"25%\" height=\"25%\" title=\"텐서\" alt=\"시계열 데이터 텐서\"></img>\n",
    "\n",
    "    ex) 주식 가격 데이터셋   \n",
    "        하루 동안의 거래: (390,3) 크기의 2D 텐서로 인코딩됨 (하루 거래 시간이 390분)\n",
    "        250일치의 데이터: (250,390,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.11 이미지 데이터\n",
    "\n",
    "높이, 너비, 컬러 채널의 3차원으로 이루어짐 (흑백 이미지는 하나의 컬러 채널만을 가져서 2D 텐서로 저장될 수 있음)   \n",
    "흑백 이미지는 컬러 채널의 차원 크기는 1   \n",
    "\n",
    "256x256 크기의 흑백 이미지에 대한 128개의 배치: (128,256,256,1)\n",
    "256x256 크기의 흑백 이미지에 대한 128개의 배치: (128,256,256,3)\n",
    "\n",
    "<img src=\"https://tensorflowkorea.files.wordpress.com/2018/12/069.jpg?w=600\" width = \"25%\" height = \"25%\"></img>\n",
    "\n",
    "* 채널 마지막 방식(텐서플로에서 사용)\n",
    "    (samples, height, width, color_depth)\n",
    "* 채널 우선 방식(씨아노에서 사용)\n",
    "    (samples, color_depth, height, width)\n",
    "    \n",
    "        케라스는 두 형식 모두 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.12 비디오 데이터\n",
    "\n",
    "하나의 비디오는 프레임의 연속, 각 프레임은 하나의 컬러 이미지 -> 5D 텐서\n",
    "\n",
    "프레임: (height, width, color_depth)   \n",
    "프레임의 연속: (frames, height, width, color_depth)   \n",
    "여러 비디오의 배치: (samples, frames, height, width, color_depth)\n",
    "\n",
    "        ex) 60초짜리 144*256 유튜브 비디오 클립을 초당 4프레임으로 샘플링하면 240 프레임이 됨\n",
    "            이런 비디오 클립을 4개 가진 배치는\n",
    "            (4,240,144,256,3)  크기의 텐서에 저장됨\n",
    "            이 텐서의 dtype를 float32로 했으면 각 값이 32비트로 저장, 텐서의 저장 크기는 405MB\n",
    "            \n",
    "<br/>            \n",
    "<br/>         \n",
    "\n",
    "***         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 신경망의 톱니바퀴: 텐서 연산\n",
    "\n",
    "심층 신경망이 학습한 모든 변환을 수치 데이터 텐서에 적용하는 몇 종류의 텐서 연산으로 나타낼 수 있음(텐서 덧셈, 텐서 곱셈 등)\n",
    "\n",
    "#### 2.3.1 원소별 연산\n",
    "\n",
    "텐서에 있는 각 원소에 독립적으로 적용됨   \n",
    "\n",
    "relu 함수와 덧셈\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 브로드캐스팅\n",
    "\n",
    "크기가 다른 두 텐서 연산할 때 모호하지 않고 실행 가능하다면 작은 텐서가 큰 텐서의 크기에 맞춰 브로드캐스팅됨\n",
    "\n",
    "1. 큰 텐서의 ndim에 맞도록 작은 텐서에 축이 추가됨\n",
    "2. 작은 텐서가 새 축을 따라 큰 텐서의 크기에 맞도록 반복됨\n",
    "\n",
    "        메모리 수준이 아니라 알고리즘 수준에서 일어남"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 텐서 점곱\n",
    "\n",
    "(텐서 곱셈) 텐서 점곱: 원소별 연산과 반대로 입력 텐서의 원소들을 결합시킴\n",
    "\n",
    "넘파이, 케라스, 씨아노, 텐서플로에서 * 연산자 사용\n",
    "\n",
    "```\n",
    "z=np.dot(x,y)\n",
    "\n",
    "z=x·y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 텐서 크기 변환\n",
    "\n",
    "특정 크기에 맞게 열과 행을 재배열   \n",
    "변환된 텐서는 원래 텐서와 원소 개수가 동일함\n",
    "\n",
    "전치: 행과 열을 바꾸는 것   \n",
    "\n",
    "    x[i,:]이 x[:,i]가 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 텐서 연산의 기하학적 해석\n",
    "\n",
    "모든 텐서 연산은 기하학적 해석이 가능함\n",
    "\n",
    "\n",
    "#### 2.3.6 딥러닝의 기하학적 해석\n",
    "\n",
    "신경망을 고차원 공간에서 매우 복잡한 기하학적 변환 하는 것으로 해석 가능\n",
    "\n",
    "심층 네트워크의 각 층은 데이터를 조금씩 풀어 주는 변환을 적용해 층을 깊게 쌓으면 복잡한 분해 과정 처리 가능\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 신경망의 엔진: 그래디언트 기반 최적화\n",
    "\n",
    "```\n",
    "output = relu(dot(W, input) + b)\n",
    "```\n",
    "\n",
    "텐서 w와 b는 층의 속성   \n",
    "가중치 또는 훈련되는 파라미터라고 부름 (커널, 편향(bias)이라고 부르기도 함)\n",
    "\n",
    "초기에는 가중치 행렬이 작은 난수로 채워져 있음(무작위 초기화 단계)   \n",
    "-> 처음에는 의미 없는 표현이 만들어짐\n",
    "\n",
    "##### 훈련 반복 루프   \n",
    "\n",
    "    1. 훈련 샘플 x와 타깃 y의 배치 추출\n",
    "    2. x를 사용해 네트워크 실행(정방향 패스 단계), 예측 y_pred를 구함\n",
    "    3. y_pred와 y의 차이를 측정해 손실 계산\n",
    "    4. 손실이 감소되도록 모든 가중치 업데이트\n",
    "    \n",
    "4단계에서 신경망에서 사용된 모든 연산이 미분 가능하단 것을 이용해 가중치에 대한 손실의 그래디언트를 계산해서 업데이트함   \n",
    "그래디언트의 반대 방향으로 가중치 이동하면 손실 감소됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 변화율이란?\n",
    "\n",
    "연속 함수에서의 기울기  \n",
    "\n",
    "기울기가 음수일 때:   \n",
    "\n",
    "    p(어떤 포인트)에서 양수 x만큼 이동 -> f(x)가 감소   \n",
    "    \n",
    "기울기가 양수일 때:   \n",
    "\n",
    "    p에서 음수 x만큼 이동 -> f(x)가 감소   \n",
    "    \n",
    "기울기의 절댓값(변화율의 크기)은 증가나 감소가 얼마나 빠를지 알려줌    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 텐서 연산의 변화율: 그래디언트\n",
    "\n",
    "텐서 연산의 변화율"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
