{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 신경망의 수학적 구성 요소\n",
    "\n",
    "## 2.1 신경망과의 첫 만남\n",
    "\n",
    "#### 흑백 손글자 이미지를 10개의 범주로 분류하는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MNIST 데이터셋을 불러와서 훈련 세트와 테스트 세트 만들고 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() #훈련 세트, 테스트 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape #훈련 데이터, 테스트 데이터 확인하기\n",
    "len(train_labels)\n",
    "train_labels\n",
    "\n",
    "test_images.shape\n",
    "len(test_labels)\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 신경망 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "#신경망 층 2개\n",
    "network.add(layers.Dense(512,activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10,activation='softmax')) #확률 점수가 들어있는 배열 반환하는 소프트맥스 층\n",
    "\n",
    "#네트워크는 2개의 Dense 층이 연결되어 있고 각 층은 가중치 텐서를 포함해 입력 데이터에 대한 간단한 텐서 연산을 몇 개 적용함\n",
    "#층의 속성인 가중치 텐서는 네트워크가 정보를 저장하는 곳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 컴파일 단계\n",
    "\n",
    "> 손실 함수(신경망 성능 측정하는 방법)   \n",
    "옵티마이저(네트워크 업데이트)   \n",
    "훈련과 테스트 과정 모니터링할 지표(지금은 정확도만 고려)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#컴파일\n",
    "#옵티마이저, 손실함수, 지표(지금은 정확도만 고려)\n",
    "network.compile(optimizer = 'rmsprop',\n",
    "               loss='categorical_crossentropy', #손실 함수, 가중치 텐서 학습을 위한 피드백으로 사용, 훈련하는 동안 최소화됨\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 이미지 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0~255 사이의 값인 uint8 타입의 (60000,28,28) 크기 가진 배열 -> 0~1 사이 값 가지는 float32 타입의 (60000,28*28) 크기 배열\n",
    "train_imgaes = train_images.reshape((60000,28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images=test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "#입력 이미지의 데이터 타입은 float32, 훈련 데이터는 (60000,784) 크기, 테스트 데이터는 (10000,784) 크기의 넘파이 배열로 저장됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 레이블 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#to_categorical: 입력받은 1차원 정수 배열 -> 2차원 배열로 변경\n",
    "train_labels=to_categorical(train_labels)\n",
    "test_labels=to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습\n",
    "\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128) #훈련 반복\n",
    "#네트워크가 128개 샘플씩 미니 배치로 훈련 데이터를 다섯 번 반복함(각 반복을 epoch라고 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#테스트\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 신경망을 위한 데이터 표현\n",
    "텐서: 데이터를 위한 컨테이너   \n",
    "      임의의 차원 개수를 가지는 행렬의 일반화된 모습(텐서에서는 차원을 축이라고도 함)\n",
    "\n",
    "#### 2.2.1 스칼라(0D 텐서)\n",
    "\n",
    "스칼라: 하나의 숫자만 담고 있는 텐서   \n",
    "        넘파이에서는 float32나 float 64 타입의 숫자   \n",
    "\n",
    "\n",
    "ndim 속성으로 넘파이 배열의 축 개수 확인 가능    \n",
    "스칼라 텐서의 축 개수는 0   \n",
    "\n",
    "랭크: 텐서의 축 개수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.array(12)\n",
    "print(x)\n",
    "print(x.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 벡터(1D 텐서)\n",
    "\n",
    "벡터: 숫자의 배열\n",
    "      하나의 축을 가짐\n",
    "      \n",
    "      5D 벡터: 하나의 축을 따라 5개의 차원 가진 것\n",
    "      5D 텐서: 5개의 축을 가진 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([12,3,6,14,7]) #5D 벡터(5차원 벡터)\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 행렬(2D 텐서)\n",
    "\n",
    "행렬: 벡터의 배열\n",
    "      2개의 축이 있음(행(가로), 렬(세로))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[5,78,2,34,0],\n",
    "           [6,79,3,35,1],\n",
    "           [7,80,4,36,2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 3D 텐서와 고차원 텐서\n",
    "\n",
    "3D 텐서: 행렬들을 하나의 새로운 배열로 합친 것(직육면체 형태)\n",
    "\n",
    "        3D 텐서들 하나의 배열로 합치면 4D 텐서   \n",
    "        딥러닝에서는 보통 0~4D까지 다룸\n",
    "        영상 데이터 다룰 때는 5D까지 가기도 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([[[5,78,2,34,0],\n",
    "           [6,79,3,35,1],\n",
    "           [7,80,4,36,2]],\n",
    "            [[5,78,2,34,0],\n",
    "           [6,79,3,35,1],\n",
    "           [7,80,4,36,2]],\n",
    "            [[5,78,2,34,0],\n",
    "           [6,79,3,35,1],\n",
    "           [7,80,4,36,2]]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.5 핵심 속성\n",
    "\n",
    "* 축의 개수(랭크)\n",
    "* 크기\n",
    "    파이썬의 튜플   \n",
    "        행렬의 크기: (3,5)   \n",
    "        3D 텐서의 크기: (3,3,5)   \n",
    "        벡터의 크기: (5,)   \n",
    "        스칼라의 크기: ()\n",
    "* 데이터 타입(넘파이에서는 dtype에 저장됨)   \n",
    "        텐서에 포함된 데이터의 타입   \n",
    "        넘파이 배열은 가변 길이의 문자열 지원 X (텐서는 사전에 할당되어 연속된 메모리에 저장되어야 해서)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(60000, 28, 28)\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() #훈련 세트, 테스트 세트\n",
    "\n",
    "print(train_images.ndim) #축의 개수 확인\n",
    "print(train_images.shape) #배열의 크기 확인\n",
    "print(train_images.dtype) #테이터 타입 확인\n",
    "\n",
    "#8비트 정수형 3D 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#다섯번째 이미지 출력\n",
    "\n",
    "digit=train_images[4]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.6 넘파이로 텐서 조작하기\n",
    "\n",
    "슬라이싱: 배열에 있는 특정 원소들 선택하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 28, 28)\n",
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#11~101번까지 (101번은 포함 X) 숫자 선택해 (90,28,28) 크기의 배열 만듬\n",
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)\n",
    "\n",
    "#동일한데 더 자세한 표기법\n",
    "#각 배열의 축을 따라서 슬라이싱의 시작과 끝 인덱스 지정\n",
    "#:은 전체 인덱스 선택\n",
    "\n",
    "my_slicee=train_images[10:100,:,:]\n",
    "print(my_slicee.shape)\n",
    "\n",
    "my_sliceee=train_images[10:100,0:28,0:28]\n",
    "print(my_sliceee.shape)\n",
    "\n",
    "#오늘쪽 아래 14*14 픽셀 선택\n",
    "my_slice=train_images[:,14:,14:]\n",
    "\n",
    "#음수 인덱스\n",
    "#현재 축의 끝에서 상대적인 위치 나타냄\n",
    "#정중앙에 위치한 14*14 픽셀 조각 잘라내기\n",
    "\n",
    "my_slice=train_images[:,7:-7,7:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.7 배치 데이터\n",
    "\n",
    "샘플 축: 딥러닝에서 사용하는 모든 데이터 텐서의 첫 번째 축 (샘플 차원)   \n",
    "\n",
    "딥러닝 모델은 데이터를 작은 배치로 나눠서 데이터셋을 처리함\n",
    "\n",
    "* MNIST에서 크기가 128인 배치 하나   \n",
    "```\n",
    "batch=train_images[:128]\n",
    "```\n",
    "* 그 다음 배치\n",
    "```\n",
    "batch=train_images[128:256]\n",
    "```\n",
    "* n번째 배치\n",
    "```\n",
    "batch=train_images[128*n:128*(n+1)]\n",
    "```\n",
    "\n",
    "첫번째 축(0번 축)을 **배치 축** 또는 **배치 차원**이라고 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.8 텐서의 실제 사례\n",
    "\n",
    "* 벡터 데이터   \n",
    "    (smaples, features) 크기의 2D 텐서\n",
    "* 시계열 데이터 또는 시퀀스 데이터   \n",
    "    (samples, timesteps, features) 크기의 3D 텐서\n",
    "* 이미지   \n",
    "    (samples, height, width, channels) 또는 (samples, channels, height, width) 크기의 4D 텐서\n",
    "* 동영상   \n",
    "    (samples, frames, height, width, channels) 또는 (samples, frames, channels, height, width) 크기의 5D 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.9 벡터 데이터\n",
    "\n",
    "대부분의 경우에 해당됨   \n",
    "하나의 데이터 포인트가 벡터로 인코딩될 수 있음   \n",
    "배치 데이터는 2D 텐서로 인코딩될 것(벡터의 배열)   \n",
    "첫 번째 축은 **샘플 축**, 두 번째 축은 **특성 축**   \n",
    "\n",
    "    ex) 사람의 나이, 우편번호, 소득으로 구성된 인구 통계 데이터.\n",
    "        10만 명이 포함된 전체 데이터셋은 (100000,3) 크기의 텐서에 저장될 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.10 시계열 데이터 또는 시퀀스 데이터\n",
    "\n",
    "데이터에서 시간이 중요할 때에는 시간 축을 포함해 3D 텐서로 저장됨   \n",
    "시간 축은 항상 두 번째 축(인덱스가 1인 축)   \n",
    "<img src=\"https://thebook.io/img/006975/068.jpg\" width=\"25%\" height=\"25%\" title=\"텐서\" alt=\"시계열 데이터 텐서\"></img>\n",
    "\n",
    "    ex) 주식 가격 데이터셋   \n",
    "        하루 동안의 거래: (390,3) 크기의 2D 텐서로 인코딩됨 (하루 거래 시간이 390분)\n",
    "        250일치의 데이터: (250,390,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.11 이미지 데이터\n",
    "\n",
    "높이, 너비, 컬러 채널의 3차원으로 이루어짐 (흑백 이미지는 하나의 컬러 채널만을 가져서 2D 텐서로 저장될 수 있음)   \n",
    "흑백 이미지는 컬러 채널의 차원 크기는 1   \n",
    "\n",
    "256x256 크기의 흑백 이미지에 대한 128개의 배치: (128,256,256,1)\n",
    "256x256 크기의 흑백 이미지에 대한 128개의 배치: (128,256,256,3)\n",
    "\n",
    "<img src=\"https://tensorflowkorea.files.wordpress.com/2018/12/069.jpg?w=600\" width = \"25%\" height = \"25%\"></img>\n",
    "\n",
    "* 채널 마지막 방식(텐서플로에서 사용)\n",
    "    (samples, height, width, color_depth)\n",
    "* 채널 우선 방식(씨아노에서 사용)\n",
    "    (samples, color_depth, height, width)\n",
    "    \n",
    "        케라스는 두 형식 모두 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.12 비디오 데이터\n",
    "\n",
    "하나의 비디오는 프레임의 연속, 각 프레임은 하나의 컬러 이미지 -> 5D 텐서\n",
    "\n",
    "프레임: (height, width, color_depth)   \n",
    "프레임의 연속: (frames, height, width, color_depth)   \n",
    "여러 비디오의 배치: (samples, frames, height, width, color_depth)\n",
    "\n",
    "        ex) 60초짜리 144*256 유튜브 비디오 클립을 초당 4프레임으로 샘플링하면 240 프레임이 됨\n",
    "            이런 비디오 클립을 4개 가진 배치는\n",
    "            (4,240,144,256,3)  크기의 텐서에 저장됨\n",
    "            이 텐서의 dtype를 float32로 했으면 각 값이 32비트로 저장, 텐서의 저장 크기는 405MB\n",
    "            \n",
    "<br/>            \n",
    "<br/>         \n",
    "\n",
    "***         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 신경망의 톱니바퀴: 텐서 연산\n",
    "\n",
    "심층 신경망이 학습한 모든 변환을 수치 데이터 텐서에 적용하는 몇 종류의 텐서 연산으로 나타낼 수 있음(텐서 덧셈, 텐서 곱셈 등)\n",
    "\n",
    "#### 2.3.1 원소별 연산\n",
    "\n",
    "텐서에 있는 각 원소에 독립적으로 적용됨   \n",
    "\n",
    "relu 함수와 덧셈\n",
    "\n",
    "넘파이는 엄청난 속도로 처리함\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "z=x+y #원소별 덧셈\n",
    "z=np.maximum(z,0.) #원소별 relu 함수\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 브로드캐스팅\n",
    "\n",
    "크기가 다른 두 텐서 연산할 때 모호하지 않고 실행 가능하다면 작은 텐서가 큰 텐서의 크기에 맞춰 브로드캐스팅됨\n",
    "\n",
    "1. 큰 텐서의 ndim에 맞도록 작은 텐서에 축이 추가됨\n",
    "2. 작은 텐서가 새 축을 따라 큰 텐서의 크기에 맞도록 반복됨\n",
    "\n",
    "        메모리 수준이 아니라 알고리즘 수준에서 일어남\n",
    "        \n",
    "        \n",
    "```\n",
    "import numpy as np\n",
    "\n",
    "x=np.random.random((64,3,32,10))\n",
    "y=np.random.random((32,10))\n",
    "\n",
    "z=np.maximum(x,y) #출력 z 크기는 x와 동일하게 (64,3,32,10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 텐서 점곱\n",
    "\n",
    "(텐서 곱셈) 텐서 점곱: 원소별 연산과 반대로 입력 텐서의 원소들을 결합시킴\n",
    "\n",
    "넘파이, 케라스, 씨아노, 텐서플로에서 * 연산자 사용\n",
    "\n",
    "```\n",
    "z=np.dot(x,y)\n",
    "\n",
    "z=x·y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 텐서 크기 변환\n",
    "\n",
    "신경망에 주이할 숫자 데이터 전처리할 때 사용\n",
    "\n",
    "특정 크기에 맞게 열과 행을 재배열   \n",
    "변환된 텐서는 원래 텐서와 원소 개수가 동일함\n",
    "\n",
    "전치: 행과 열을 바꾸는 것   \n",
    "\n",
    "    x[i,:]이 x[:,i]가 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 텐서 연산의 기하학적 해석\n",
    "\n",
    "모든 텐서 연산은 기하학적 해석이 가능함\n",
    "\n",
    "\n",
    "#### 2.3.6 딥러닝의 기하학적 해석\n",
    "\n",
    "신경망을 고차원 공간에서 매우 복잡한 기하학적 변환 하는 것으로 해석 가능\n",
    "\n",
    "심층 네트워크의 각 층은 데이터를 조금씩 풀어 주는 변환을 적용해 층을 깊게 쌓으면 복잡한 분해 과정 처리 가능\n",
    "\n",
    "<br/>            \n",
    "<br/>         \n",
    "\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 신경망의 엔진: 그래디언트 기반 최적화\n",
    "\n",
    "```\n",
    "output = relu(dot(W, input) + b)\n",
    "```\n",
    "\n",
    "텐서 w와 b는 층의 속성   \n",
    "가중치 또는 훈련되는 파라미터라고 부름 (커널, 편향(bias)이라고 부르기도 함)\n",
    "\n",
    "초기에는 가중치 행렬이 작은 난수로 채워져 있음(무작위 초기화 단계)   \n",
    "-> 처음에는 의미 없는 표현이 만들어짐\n",
    "\n",
    "##### 훈련 반복 루프   \n",
    "\n",
    "    1. 훈련 샘플 x와 타깃 y의 배치 추출\n",
    "    2. x를 사용해 네트워크 실행(정방향 패스 단계), 예측 y_pred를 구함\n",
    "    3. y_pred와 y의 차이를 측정해 손실 계산\n",
    "    4. 손실이 감소되도록 모든 가중치 업데이트\n",
    "    \n",
    "4단계에서 신경망에서 사용된 모든 연산이 미분 가능하단 것을 이용해 가중치에 대한 손실의 그래디언트를 계산해서 업데이트함   \n",
    "그래디언트의 반대 방향으로 가중치 이동하면 손실 감소됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 변화율이란?\n",
    "\n",
    "연속 함수에서의 기울기  \n",
    "\n",
    "기울기가 음수일 때:   \n",
    "\n",
    "    p(어떤 포인트)에서 양수 x만큼 이동 -> f(x)가 감소   \n",
    "    \n",
    "기울기가 양수일 때:   \n",
    "\n",
    "    p에서 음수 x만큼 이동 -> f(x)가 감소   \n",
    "    \n",
    "기울기의 절댓값(변화율의 크기)은 증가나 감소가 얼마나 빠를지 알려줌    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 텐서 연산의 변화율: 그래디언트\n",
    "\n",
    "그래디언트: 텐서 연산의 변화율\n",
    "            gradient(f)(w0)는 w0에서 f(w)의 기울기를 나타내는 텐서\n",
    "            \n",
    "함수 f(x)에서 변화율의 반대 방향으로 x를 움직이면 f(x)의 값 감소시킬 수 있음    \n",
    "f(w)에서 그래디언트 반대 방향으로 w 움직이면 f(w) 값 줄일 수 있음\n",
    "\n",
    "\n",
    "w1=w0-step*gradient(f)(w0)\n",
    "\n",
    "step: 스케일 조정 위한 작은 값\n",
    "      gradient(f)(w0)은 w0에 아주 가까이 있을 때 기울기 근사한 거라서 w0에서 너무 벗어나지 않게 하려고 step이 필요함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4.3 확률적 경사 하강법\n",
    "\n",
    "미분 가능한 함수가 있으면 최솟값(변화율이 0인 지점)을 구할 수 있음   \n",
    "변화율이 0인 지점을 모두 찾고 이 중 어떤 포인트의 함수값이 가장 작은지 확인\n",
    "\n",
    "신경망에서는 가장 작은 손실 함수의 값을 만드는 가중치 조합을 찾는 것   \n",
    "gradient(f)(w)=0을 풀면 됨\n",
    "\n",
    "**미니 배치 확률적 경사 하강법(미니배치 SGD)**\n",
    "1. 훈련 샘플 배치 x와 이에 상응하는 타깃 y 추출\n",
    "2. x로 네트워크 실행 후 예측 y_pred 구함\n",
    "3. 이 배치에서 y_pred와 y 사이의 오차 측정해 네트워크 손실 계산\n",
    "4. 네트워크의 파라미터에 대한 손실 함수의 그래디언트 계산(역방향 패스)\n",
    "5. 그래디언트 반대 방향으로 파라미터 조금 이동시킴 (w-=step*gradient)\n",
    "        확률적: 각 배치 데이터가 무작위로 선택\n",
    "\n",
    "step 값이 너무 작으면 많이 반복, 지역 최솟값에 갇힐 수 있음   \n",
    "step 값이 너무 크면 손실 함수 곡선에서 완전 임의의 위치로 이동시킬 수 있음\n",
    "\n",
    "진정한 SGD: 반복마다 하나의 샘플과 타깃 뽑는 것   \n",
    "배치 SGD: 가용한 모든 데이터 사용해 반복 실행 -> 더 정확히 업데이트, 더 많은 비용 듬   \n",
    "-> 절충안: 적절한 크기의 미니 배치 사용하는 것\n",
    "\n",
    "**저차원 표현으로 얻은 직관이 실전과 항상 맞지는 않음!!**\n",
    "\n",
    "업데이트할 다음 가중치 계산할 때 이전에 업데이트된 가중치를 다른 방식으로 고려하는 SGD 변종이 있음   \n",
    "모멘텀을 사용한 SGD, Adagrad, RMSProp 등을 **최적화 방법(옵티마이저)** 이라고 함\n",
    "\n",
    "모멘텀: SGD의 문제점인 수렴 속도와 지역 최솟값을 해결함   \n",
    "        모멘텀이 충분하면 지역 최솟값에 갇히지 않고 전역 최솟값에 도달 가능\n",
    "        현재 기울기 값(현재 가속도)와 (과거의 가속도로 인한) 현재 속도를 함께 고려함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.4 변화율 연결: 역전파 알고리즘\n",
    "\n",
    "f(w1,w2,w3) = a(w1,b(w2,c(w3)))   \n",
    "3개의 텐서 연산 a,b,c와 가중치 행렬 w1,w2,w3으로 구성된 네트워크 f\n",
    "\n",
    "이렇게 연결된 함수는 연쇄 법칙을 사용해 유도 가능\n",
    "\n",
    "연쇄 법칙: 항등식 f(g(x))'=f'(g(x)) * g'(x)\n",
    "\n",
    "연쇄 법칙을 신경망의 그래디언트 계산에 적용해 역전파 알고리즘(후진 모드 자동 미분)이 탄생함\n",
    "\n",
    "역전파: 최종 손실 값에서부터 시작해 연쇄 법칙을 적용해 최상위 층에서 하위 층까지 거꾸로 진행됨\n",
    "\n",
    "<br/>\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
